{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "942ef973-27c6-476b-8240-a97d46525444",
   "metadata": {},
   "source": [
    "# Project CNN Plants Disease Detection\n",
    "**by Yassine MEKRANY**\n",
    "\n",
    "---\n",
    "\n",
    "Welcome to the **CNN Plants Disease Detection** project notebook! 🌿🔍\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c7d018-006d-4246-90a3-07cd9677b04a",
   "metadata": {},
   "source": [
    "## 1. Import Libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "136ea173-af76-4ac0-ae54-60057340f9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from PIL import Image\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85378428-4297-4dfc-aa31-e5caa015e870",
   "metadata": {},
   "source": [
    "## 2. Set Up Data Generators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29f34b71-5c43-40d6-899e-df7b5b9957bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12881 images belonging to 2 classes.\n",
      "Found 3219 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Define paths to data directory \n",
    "data_dir = 'data'\n",
    "\n",
    "# Create data generators with data augmentation for training and normalization for validation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    validation_split=0.2  # 20% of the data will be used for validation\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)  # Same 20% split for testing\n",
    "\n",
    "# Load images for training (80% of data)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    subset='training'  # 80% training data\n",
    ")\n",
    "\n",
    "# Load images for testing (20% of data)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    subset='validation'  # 20% test/validation data\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece2e6e5-9774-44fa-9177-c8d2eda345d2",
   "metadata": {},
   "source": [
    "## 3. Build the CNN Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbed07ef-3866-4120-a629-7b89644bf059",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49956619-2677-4e8b-ab26-3ecb143c8012",
   "metadata": {},
   "source": [
    "## 4. Compile the Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cfb7c5f-3520-4f93-99fd-f610ad12ea19",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=Adam(),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fabb6f5-505a-40f3-a16d-63590d5f6378",
   "metadata": {},
   "source": [
    "## 5. Train the Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "596c615a-d76a-455c-a044-0edc09abd6bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m577s\u001b[0m 1s/step - accuracy: 0.6782 - loss: 0.5806 - val_accuracy: 0.7625 - val_loss: 0.5341\n",
      "Epoch 2/20\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 528us/step - accuracy: 0.9062 - loss: 0.2901 - val_accuracy: 0.5789 - val_loss: 0.7261\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\anaconda3\\Lib\\contextlib.py:158: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m520s\u001b[0m 1s/step - accuracy: 0.8577 - loss: 0.3544 - val_accuracy: 0.7578 - val_loss: 0.5208\n",
      "Epoch 4/20\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 557us/step - accuracy: 0.8125 - loss: 0.7693 - val_accuracy: 0.7895 - val_loss: 0.4393\n",
      "Epoch 5/20\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m622s\u001b[0m 2s/step - accuracy: 0.8833 - loss: 0.2907 - val_accuracy: 0.7869 - val_loss: 0.5171\n",
      "Epoch 6/20\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 642us/step - accuracy: 0.8438 - loss: 0.3433 - val_accuracy: 0.7895 - val_loss: 0.3936\n",
      "Epoch 7/20\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m758s\u001b[0m 2s/step - accuracy: 0.8953 - loss: 0.2609 - val_accuracy: 0.7781 - val_loss: 0.5582\n",
      "Epoch 8/20\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8750 - loss: 0.3747 - val_accuracy: 0.8421 - val_loss: 0.3222\n",
      "Epoch 9/20\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m659s\u001b[0m 2s/step - accuracy: 0.8975 - loss: 0.2558 - val_accuracy: 0.8159 - val_loss: 0.3601\n",
      "Epoch 10/20\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 647us/step - accuracy: 0.7812 - loss: 0.3017 - val_accuracy: 0.6316 - val_loss: 0.9264\n",
      "Epoch 11/20\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m625s\u001b[0m 2s/step - accuracy: 0.9054 - loss: 0.2385 - val_accuracy: 0.8238 - val_loss: 0.3060\n",
      "Epoch 12/20\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 637us/step - accuracy: 0.8750 - loss: 0.1780 - val_accuracy: 0.7368 - val_loss: 0.5317\n",
      "Epoch 13/20\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m622s\u001b[0m 2s/step - accuracy: 0.9100 - loss: 0.2224 - val_accuracy: 0.8094 - val_loss: 0.3291\n",
      "Epoch 14/20\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 803us/step - accuracy: 0.9375 - loss: 0.1840 - val_accuracy: 0.8421 - val_loss: 0.2924\n",
      "Epoch 15/20\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m726s\u001b[0m 2s/step - accuracy: 0.9222 - loss: 0.2028 - val_accuracy: 0.7897 - val_loss: 0.4274\n",
      "Epoch 16/20\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9062 - loss: 0.3079 - val_accuracy: 0.8947 - val_loss: 0.2617\n",
      "Epoch 17/20\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m680s\u001b[0m 2s/step - accuracy: 0.9269 - loss: 0.1844 - val_accuracy: 0.8084 - val_loss: 0.3493\n",
      "Epoch 18/20\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8750 - loss: 0.2471 - val_accuracy: 0.7368 - val_loss: 0.4082\n",
      "Epoch 19/20\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m528s\u001b[0m 1s/step - accuracy: 0.9255 - loss: 0.1948 - val_accuracy: 0.7738 - val_loss: 0.4430\n",
      "Epoch 20/20\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 449us/step - accuracy: 0.9375 - loss: 0.2646 - val_accuracy: 0.7368 - val_loss: 0.7285\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    epochs=20,\n",
    "    validation_data=test_generator,\n",
    "    validation_steps=test_generator.samples // test_generator.batch_size\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776ac4f7-215a-42c6-b919-72a1c4e7dc22",
   "metadata": {},
   "source": [
    "## 6. Evaluate the Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ff812c5-6387-4feb-8d2b-8e215416432a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 216ms/step - accuracy: 0.7756 - loss: 0.4476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 77.48%\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(test_generator)\n",
    "print(f'Test accuracy: {accuracy*100:.2f}%')\n",
    "\n",
    "model.save('binary_plant_disease_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69152d35-0697-49b3-a69e-089b8080cb06",
   "metadata": {},
   "source": [
    "## 7. Upload an Image to Predict Health Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1723d648-f1b2-48ea-a521-198720641233",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7865\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7865/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 231ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n"
     ]
    }
   ],
   "source": [
    "# Load the pre-trained model\n",
    "model = tf.keras.models.load_model('binary_plant_disease_model.h5')\n",
    "\n",
    "# Define a function to preprocess the uploaded image\n",
    "def preprocess_image(image):\n",
    "    image = image.resize((150, 150))  # Resize image to match model input\n",
    "    image_array = np.array(image) / 255.0  # Normalize image\n",
    "    image_array = np.expand_dims(image_array, axis=0)  # Add batch dimension\n",
    "    return image_array\n",
    "\n",
    "# Define a function to predict the class of the image\n",
    "def predict(image):\n",
    "    image_array = preprocess_image(image)\n",
    "    prediction = model.predict(image_array)\n",
    "    return \"Healthy\" if prediction[0] > 0.5 else \"Diseased\"\n",
    "\n",
    "# Define a function to format the output with color and language support\n",
    "def classify_image(image, language):\n",
    "    result = predict(image)\n",
    "    \n",
    "    if result == \"Healthy\":\n",
    "        result_text = \"This plant is Healthy\" if language == \"English\" else \"Cette plante est saine\" if language == \"French\" else \"هذا النبات معافى\"\n",
    "        return f\"<span style='color:green'>{result_text}</span>\"\n",
    "    else:\n",
    "        result_text = \"This plant is Diseased\" if language == \"English\" else \"Cette plante est malade\" if language == \"French\" else \"هذا النبات مريض\"\n",
    "        return f\"<span style='color:red'>{result_text}</span>\"\n",
    "\n",
    "# Define the Gradio interface\n",
    "interface = gr.Interface(\n",
    "    fn=classify_image, \n",
    "    inputs=[gr.Image(type=\"pil\"), gr.Dropdown(choices=[\"English\", \"French\", \"Arabic\"], label=\"Language\")], \n",
    "    outputs=gr.HTML(),\n",
    "    title=\"Plant Disease Classification\",\n",
    "    description=\"Upload an image of a plant leaf to predict if it is Healthy or Diseased, \\n and select the language for the result.\"\n",
    ")\n",
    "\n",
    "# Launch the interface\n",
    "interface.launch()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
